from airflow import DAG
from airflow.models.param import Param
from operators.oracle_to_s3 import OracleToS3ParquetOperator
from operators.s3_to_postgres import S3ParquetToPostgresOperator
import pendulum
from datetime import timedelta

# =========================================================
# ğŸ“ [ê°œë°œì ì˜ì—­] ì„¤ì •
# =========================================================

# 1. Oracle ì¡°íšŒ ì¿¼ë¦¬ (ë‚ ì§œ ë³€ìˆ˜ ì—†ìŒ -> ì „ì²´ ì¡°íšŒ)
SOURCE_SQL = """
    SELECT SALES_REGION_CODE
     , SALES_REGION_EN
     , SALES_REGION_AR
     , SALES_REGION_CS
     , SALES_REGION_DA
     , SALES_REGION_DE
     , SALES_REGION_EL
     , SALES_REGION_ES
     , SALES_REGION_FI
     , SALES_REGION_FR
     , SALES_REGION_HR
     , SALES_REGION_HU
     , SALES_REGION_ID
     , SALES_REGION_IT
     , SALES_REGION_JA
     , SALES_REGION_KK
     , SALES_REGION_KO
     , SALES_REGION_MS
     , SALES_REGION_NL
     , SALES_REGION_NO
     , SALES_REGION_PL
     , SALES_REGION_PT
     , SALES_REGION_RO
     , SALES_REGION_RU
     , SALES_REGION_SC
     , SALES_REGION_SL
     , SALES_REGION_SV
     , SALES_REGION_TC
     , SALES_REGION_TH
     , SALES_REGION_TR
     , SYSDATE AS ETL_CRY_DTM
  FROM GOSALES.SALES_REGION
"""

# 2. ì ì¬ í…Œì´ë¸” ì´ë¦„
TARGET_TABLE = "sales_region"

# 3. ë‚ ì§œ ê¸°ì¤€ ì»¬ëŸ¼
# - ê°’ì´ ìˆìœ¼ë©´ (ì˜ˆ: 'REG_DATE'): ê¸°ê°„ë³„ DELETE í›„ ì ì¬
# - ê°’ì´ ì—†ìœ¼ë©´ (None): ì „ì²´ TRUNCATE í›„ ì ì¬ (ë‹¨, ë‚ ì§œ íŒŒë¼ë¯¸í„°ê°€ ì—†ì–´ì•¼ í•¨)
DATE_COLUMN = None  # ë§ˆìŠ¤í„° í…Œì´ë¸”ì´ë¯€ë¡œ None

# =========================================================

default_args = {
    'owner': 'airflow',
    'start_date': pendulum.datetime(2023, 1, 1, tz="Asia/Seoul"),
    'catchup': False,
    'execution_timeout': timedelta(hours=5)
}

# UI íŒŒë¼ë¯¸í„° ì„¤ì • (ë‚ ì§œë¥¼ ë¹„ìš¸ ìˆ˜ ìˆê²Œ typeì— null ì¶”ê°€)
params = {
    "from_date": Param(None, type=["string", "null"], description="ì‹œì‘ì¼ (ë¹„ìš°ë©´ Full Load)"),
    "to_date": Param(None, type=["string", "null"], description="ì¢…ë£Œì¼ (ë¹„ìš°ë©´ Full Load)"),
    "target_table": Param(TARGET_TABLE, type="string", description="Postgres ì ì¬ í…Œì´ë¸”ëª…")
}

with DAG(
    dag_id='dag_oracle23ai_GOSALES_SALES_REGION_20260219_143716',
    default_args=default_args,
    schedule=None,
    params=params,
    tags=['portfolio', 'oracle', 's3', 'postgres', 'hybrid_config'],
) as dag:

    # 1. Oracle -> S3
    extract_task = OracleToS3ParquetOperator(
        task_id='extract_oracle_to_s3',
        oracle_conn_id='oracle_conn',
        s3_conn_id='minio_conn',
        bucket_name='bronze',
        
        oracle_sql=SOURCE_SQL,
        
        from_date='{{ params.from_date }}',
        to_date='{{ params.to_date }}',
        s3_key_prefix='{{ params.target_table | lower }}'
    )

    # 2. S3 -> Postgres
    load_task = S3ParquetToPostgresOperator(
        task_id='load_s3_to_postgres',
        postgres_conn_id='postgres_default',
        minio_conn_id='minio_conn',
        bucket_name='bronze',
        
        target_table='{{ params.target_table }}',
        from_date='{{ params.from_date }}',
        to_date='{{ params.to_date }}',
        key_prefix='{{ params.target_table | lower }}',
        
        # â–¼ ìƒë‹¨ì—ì„œ ì •ì˜í•œ ë³€ìˆ˜ë¥¼ ë„˜ê²¨ì¤ë‹ˆë‹¤.
        date_column=DATE_COLUMN,
        
        batch_size=100000
    )

    extract_task >> load_task