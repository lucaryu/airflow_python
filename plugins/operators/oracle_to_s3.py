from airflow.models import BaseOperator
from airflow.providers.oracle.hooks.oracle import OracleHook
from airflow.providers.amazon.aws.hooks.s3 import S3Hook
import pandas as pd
import pendulum
import io
import oracledb

class OracleToS3ParquetOperator(BaseOperator):
    """
    [Custom Operator]
    Oracle ë°ì´í„°ë¥¼ ì¡°íšŒí•˜ì—¬ S3(MinIO)ì— Parquet í¬ë§·ìœ¼ë¡œ ì €ì¥
    íŒŒì¼ëª… í˜•ì‹: yellow_tripdata_YYYY-MM.parquet (Postgres ì ì¬ í˜¸í™˜ìš©)
    """
    
    template_fields = ('from_date', 'to_date', 'bucket_name', 'oracle_table')

    def __init__(
        self,
        oracle_conn_id,
        s3_conn_id,
        oracle_table,
        bucket_name,
        from_date,
        to_date,
        s3_key_prefix='taxi',
        *args,
        **kwargs
    ):
        super().__init__(*args, **kwargs)
        self.oracle_conn_id = oracle_conn_id
        self.s3_conn_id = s3_conn_id
        self.oracle_table = oracle_table
        self.bucket_name = bucket_name
        self.from_date = from_date
        self.to_date = to_date
        self.s3_key_prefix = s3_key_prefix

    def _get_oracle_conn(self):
        # OracleHookì€ ì—°ê²° ì •ë³´ ì¡°íšŒìš©ìœ¼ë¡œë§Œ ì‚¬ìš© (Wallet ì—ëŸ¬ ë°©ì§€)
        oracle_hook = OracleHook(oracle_conn_id=self.oracle_conn_id)
        conn_info = oracle_hook.get_connection(self.oracle_conn_id)
        
        service_name = conn_info.schema if conn_info.schema else 'Oracle23ai'
        dsn = f"{conn_info.host}:{conn_info.port}/{service_name}"
        
        # oracledbë¡œ ì§ì ‘ ì—°ê²°
        conn = oracledb.connect(
            user=conn_info.login,
            password=conn_info.password,
            dsn=dsn
        )
        return conn

    def execute(self, context):
        self.log.info(f"ğŸš€ [OracleToS3] ì‹œì‘: {self.from_date} ~ {self.to_date}")
        
        try:
            start_dt = pendulum.from_format(str(self.from_date), 'YYYYMMDD')
            end_dt = pendulum.from_format(str(self.to_date), 'YYYYMMDD')
        except ValueError:
            start_dt = pendulum.parse(str(self.from_date))
            end_dt = pendulum.parse(str(self.to_date))

        current_dt = start_dt
        s3_hook = S3Hook(aws_conn_id=self.s3_conn_id)
        
        # DB ì—°ê²°
        oracle_conn = self._get_oracle_conn()

        try:
            while current_dt <= end_dt:
                year = current_dt.format('YYYY')
                month = current_dt.format('MM')
                
                next_month = current_dt.add(months=1).format('YYYY-MM-01')
                current_month_str = current_dt.format('YYYY-MM-01')
                
                # ë‚ ì§œ í•„í„°ë§ ì¡°íšŒ SQL
                sql = f"""
                    SELECT * FROM {self.oracle_table}
                    WHERE TPEP_PICKUP_DATETIME >= TO_DATE('{current_month_str}', 'YYYY-MM-DD')
                      AND TPEP_PICKUP_DATETIME < TO_DATE('{next_month}', 'YYYY-MM-DD')
                """
                
                self.log.info(f"ğŸ” Oracle ì¡°íšŒ ì¤‘... ({year}-{month})")
                
                # Pandasë¡œ ë°ì´í„° ì½ê¸°
                df = pd.read_sql(sql, oracle_conn)
                
                if df.empty:
                    self.log.warning(f"âš ï¸ ë°ì´í„° ì—†ìŒ (Skip): {year}-{month}")
                else:
                    # Parquet ë³€í™˜ (ë©”ëª¨ë¦¬ ë²„í¼)
                    parquet_buffer = io.BytesIO()
                    df.to_parquet(parquet_buffer, index=False, engine='pyarrow')
                    parquet_buffer.seek(0)
                    
                    # â–¼â–¼â–¼ [ìˆ˜ì •] íŒŒì¼ëª…ì„ yellow_tripdata_YYYY-MM.parquet ë¡œ í†µì¼ â–¼â–¼â–¼
                    filename = f"yellow_tripdata_{year}-{month}.parquet"
                    s3_key = f"{self.s3_key_prefix}/year={year}/month={month}/{filename}"
                    # â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²
                    
                    s3_hook.load_bytes(
                        bytes_data=parquet_buffer.getvalue(),
                        key=s3_key,
                        bucket_name=self.bucket_name,
                        replace=True
                    )
                    self.log.info(f"âœ… S3 ì—…ë¡œë“œ ì™„ë£Œ: {s3_key} ({len(df)}ê±´)")

                current_dt = current_dt.add(months=1)
                
        finally:
            if oracle_conn:
                oracle_conn.close()